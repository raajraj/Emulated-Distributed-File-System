# -*- coding: utf-8 -*-
"""mysql.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-IAkbAn_k-mzDxp4vDBmtfQn-KlFP1ZJ
"""

# DB instance identifier: database-1
# username: admin
# pass: 12345678
# host: database-1.ctmjxsjl9mbd.us-east-1.rds.amazonaws.com
# port: 6033

import csv
import pandas as pd
import string
import pymysql

from flask import Blueprint, jsonify, request


MYSQL_API_BASE = "/mysql"

mysql_api = Blueprint('mysql', __name__,
                        template_folder='templates')

db = pymysql.connect(user="admin",
                     host="database-1.ctmjxsjl9mbd.us-east-1.rds.amazonaws.com",
                     password="12345678",
                     port=6033,
                     local_infile=1)

cursor = db.cursor()

# creates/connects entire database and creates MySQL Directory Table and MySQL Partitions Table
# fid|name|parent|parentid|content|file
# pid|fid|tableName|partition_name|part

# sql = "DROP DATABASE IF EXISTS mydatabase"
# cursor.execute(sql)

sql = "CREATE DATABASE IF NOT EXISTS mydatabase"
cursor.execute(sql)

cursor.connection.commit()

sql = "USE mydatabase"
cursor.execute(sql)

sql = "CREATE TABLE IF NOT EXISTS dir (fid int AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255), parent VARCHAR(255), parentid int, content VARCHAR(255), file VARCHAR(255))"
cursor.execute(sql)

sql = "CREATE TABLE IF NOT EXISTS partitions (pid int AUTO_INCREMENT PRIMARY KEY, file_id int NOT NULL, tableName VARCHAR(255), partition_name VARCHAR(255), part int NOT NULL, FOREIGN KEY (file_id) REFERENCES dir(fid) ON DELETE CASCADE)"
cursor.execute(sql)

sql = "INSERT into dir (name, parent, parentid, content, file) VALUES ('root', '', 0, '/', '')"
cursor.execute(sql)

db.commit()


def dir():
    sql = "select * from dir"
    cursor.execute(sql)
    results = cursor.fetchall()
    df = pd.DataFrame(results, columns=[
                      'fid', 'name', 'parent', 'parentid', 'content', 'file'])
    print(df)
    db.commit()


dir()


def partitions():
    sql = "select * from partitions"
    cursor.execute(sql)
    results = cursor.fetchall()
    df = pd.DataFrame(results, columns=[
                      'pid', 'file_id', 'tableName', 'partition_name', 'part'])
    print(df)
    db.commit()


partitions()


def fileExists(filename):
    if ("/" not in filename):
        filename = "/" + filename
    cursor.execute("SELECT * FROM dir WHERE content LIKE '" + filename + "'")
    f = cursor.fetchall()
    if (len(f) != 0):
        return 1
    return 0


def partitionExists(table, partitions):
    cursor.execute("SELECT * FROM partitions WHERE tableName LIKE '" +
                   table + "' AND part = " + str(partitions))
    result = cursor.fetchall()
    if (len(result) == 0):
        return 0
    return 1

def init_mkdir(dirname):
    if (fileExists(dirname)):
        return "error: file already exists"
    if ("/" not in dirname):
        name = dirname
        parent = "root"
        parentid = '1'
        content = "/" + dirname
    else:
        name = dirname.split('/')[-1]
        content = dirname
        if (dirname.split('/')[-2]):
            parent = dirname.split('/')[-2]
            if (not fileExists(parent)):
                return "error: parent directory not made"
            cursor.execute(
                "SELECT fid FROM dir WHERE name LIKE '" + parent + "'")
            result = cursor.fetchall()
            parentid = result[0][0]
        else:
            parent = "root"
            parentid = '1'
    file = ""
    sql = "INSERT INTO dir (name, parent, parentid, content, file) VALUES (%s, %s, %s, %s, %s)"
    val = (name, parent, int(parentid), content, file)
    cursor.execute(sql, val)
    db.commit()
    return "directory created successfully!"

@mysql_api.route(f"{MYSQL_API_BASE}/mkdir")
def mkdir():
    dirname = request.args.get('path')
    if (fileExists(dirname)):
        return jsonify({"status": "error: directory already exists"})
    if ("/" not in dirname):
        name = dirname
        parent = "root"
        parentid = '1'
        content = "/" + dirname
    else:
        name = dirname.split('/')[-1]
        content = dirname
        if (dirname.split('/')[-2]):
            parent = dirname.split('/')[-2]
            if (not fileExists(parent)):
                return jsonify({"status": "error: parent directory not made"})
            cursor.execute(
                "SELECT fid FROM dir WHERE name LIKE '" + parent + "'")
            result = cursor.fetchall()
            parentid = result[0][0]
        else:
            parent = "root"
            parentid = '1'
    file = ""
    sql = "INSERT INTO dir (name, parent, parentid, content, file) VALUES (%s, %s, %s, %s, %s)"
    val = (name, parent, int(parentid), content, file)
    cursor.execute(sql, val)
    db.commit()
    return jsonify({"status": "directory created successfully!"})


init_mkdir("/user")
init_mkdir("/user/raaj")

dir()


@mysql_api.route(f"{MYSQL_API_BASE}/ls")
def ls():
    dirname = request.args.get('path')
    cursor.execute("SELECT fid FROM dir WHERE content LIKE '" + dirname + "'")
    result = cursor.fetchall()
    dirid = result[0][0]
    sql = "SELECT name, file FROM dir WHERE parentid = " + str(dirid)
    cursor.execute(sql)
    myresult = cursor.fetchall()
    db.commit()
    output = {"directories": [], "files": []}
    print("files in directory '" + dirname + "':\n")
    for x in myresult:
        if x[1] == "":
            # file not present, means this is a directory
            output["directories"].append(x[0])
        else:
            output["files"].append(x[0])
        print(x)
    return jsonify(output)


# rm & put
# def rm(filename):
#     if("/" not in filename):
#         filename = "/" + filename
#     sql = "DELETE FROM dir WHERE content LIKE '" + filename + "'";
#     cursor.execute(sql)
#     db.commit()
# rm("/user/raaj")
# ls("/user")


@mysql_api.route(f"{MYSQL_API_BASE}/put", methods=["POST"])
def put():
    # read file
    filedata = request.files.get('file')
    filename = filedata.filename
    dirname = request.form.get('dirpath')
    k = request.form.get('numpart')

    k = int(k)

    data = pd.read_csv(filename) 
    data.to_csv("sqltable.csv")
    df = pd.DataFrame(data)
    tableName = filename.split('/')[-1]
    tableName = tableName.split('.')[-2]
    cursor.execute("DROP TABLE IF EXISTS " + tableName)
    db.commit()

    # create file in dir and partition table
    if(dirname == "/" or dirname == ""):
        name = filename.split('/')[-1]
        content = "/" + filename.split('/')[-1]
        parent = "root"
        parentid = "1"
    elif("/" not in dirname):
        name = filename.split('/')[-1]
        content = "/" + dirname + "/" + filename.split('/')[-1]
        parent = dirname
        cursor.execute("SELECT fid FROM dir WHERE name LIKE '" + parent + "'")
        result = cursor.fetchall()
        parentid = result[0][0]
    else:
        name = filename.split('/')[-1]
        content = dirname + "/" + filename.split('/')[-1]
        if(dirname.split('/')[-1]):
            parent = dirname.split('/')[-1]
            cursor.execute("SELECT fid FROM dir WHERE name LIKE '" + parent + "'")
            result = cursor.fetchall()
            parentid = result[0][0]
        else:
            parent = "root"
            parentid = "1"

    file = tableName
    if(fileExists(content)):
        return "file already exists there"
    sql = "INSERT INTO dir (name, parent, parentid, content, file) VALUES (%s, %s, %s, %s, %s)"
    val = (name, parent, int(parentid), content, file)
    cursor.execute(sql, val)
    db.commit()
    
    
    # create table
    print("processing " + tableName + " into directory...")
    sql = "CREATE TABLE " + tableName + " (tid int AUTO_INCREMENT PRIMARY KEY) PARTITION BY KEY(tid) PARTITIONS " + str(k)
    cursor.execute(sql)
    db.commit()
    prev_col = "tid"
    columns = ""
    questionMarks = ""
    for col in df.columns:
        col = col.translate(str.maketrans('', '', string.punctuation)).replace(" ", "")
        if(col == "Long"):
            col = "longi"
        sql = "ALTER TABLE " + tableName + " ADD COLUMN " + col + " VARCHAR(255) AFTER " + prev_col
        cursor.execute(sql)
        db.commit()
        prev_col = col
        columns = columns + col + ","
        questionMarks = questionMarks + "%s,"
    file = open(filename)
    csv_data = csv.reader(file)
    skipHeader = True
    
    
    sql = "LOAD DATA LOCAL INFILE 'sqltable.csv' INTO TABLE " + tableName +  " FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\n' IGNORE 1 ROWS"
    cursor.execute(sql)

    '''
    # insert data into table 
    for row in csv_data:
        if skipHeader:
            skipHeader = False
            continue
        cursor.execute('INSERT INTO ' + tableName + ' ('+  columns[:-1] + ')' 'VALUES (' + questionMarks[:-1] + ')', row)
        db.commit()
    '''
    # create partition tables
    sql = "SELECT fid FROM dir WHERE content LIKE '" + content + "'"
    cursor.execute(sql)
    
    fid = cursor.fetchall()
    
    for x in range(k):
        partitionName = tableName + "_" + str(x)
        cursor.execute("DROP TABLE IF EXISTS " + partitionName)
        cursor.execute("CREATE TABLE " + partitionName + " SELECT * FROM " + tableName + " PARTITION(p" + str(x) + ")")
        sql = "INSERT INTO partitions (file_id, tableName, partition_name, part) VALUES (" + str(fid[-1][0]) + ", '" + tableName + "','" + partitionName + "', " + str(x+1) + ")"
        cursor.execute(sql)
        db.commit()
    
    return jsonify({"status": "File uploaded successfully!"})


@mysql_api.route(f'{MYSQL_API_BASE}/cat')
def cat():
    filename = request.args.get('file')
    # check if file exists
    if(not fileExists(filename)):
        dir()
        return jsonify({"status":"file does not exist"});
    
    # get table name and columns 
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    cursor.execute("SHOW columns FROM "+ tableName[0][0])
    columns = [column[0] for column in cursor.fetchall()]
    
    # display table
    sql = "SELECT * FROM " + tableName[0][0]
    cursor.execute(sql)
    results = cursor.fetchall()
    df = pd.DataFrame(results, columns=columns)
    df['json'] = df.apply(lambda x: x.to_json(), axis=1)

    result = []
    for i in range(len(df)):
        result.append(df.loc[i, "json"])

    return jsonify(result)

@mysql_api.route(f"{MYSQL_API_BASE}/rm")
def rm():
    filename = request.args.get("path")
    if("/" not in filename):
        filename = "/" + filename
    sql = "DELETE FROM dir WHERE content LIKE '" + filename + "'";
    cursor.execute(sql)
    db.commit()
    return jsonify({"status":"OK"})


@mysql_api.route(f"{MYSQL_API_BASE}/getpartitionLocations")
def getPartitionLocations():
    filename = request.args.get('file')
    # check for file validity
    if(not fileExists(filename)):
        return jsonify({"status": "file does not exist"})
    if("/" not in filename):
        filename = "/" + filename
        
    # get file id
    sql = "SELECT fid FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    fid = cursor.fetchall()
    
    # get partitions
    sql = "SELECT pid FROM partitions WHERE file_id LIKE " + str(fid[-1][0]) 
    cursor.execute(sql)
    
    result = cursor.fetchall()
    print("partition ID(s): ")
    
    output = {}
    for x in result:
        output[filename] = x[0]
        print(x[0])
    print("\n")
    return jsonify(output)


def _getPartitionLocations(filename):
    # check for file validity
    if(not fileExists(filename)):
        return "file does not exist"
    if("/" not in filename):
        filename = "/" + filename
        
    # get file id
    sql = "SELECT fid FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    fid = cursor.fetchall()
    
    # get partitions
    sql = "SELECT pid FROM partitions WHERE file_id LIKE " + str(fid[-1][0]) 
    cursor.execute(sql)
    
    result = cursor.fetchall()
    print("partition ID(s): ")
    for x in result:
        print(x[0])
    print("\n")
    return result


@mysql_api.route(f"{MYSQL_API_BASE}/readPartition")
def readPartition():
    filename = request.args.get('file')
    partition = request.args.get('partNumber')
    # check validity of file
    if(not fileExists(filename)):
        return "file does not exist"
    if("/" not in filename):
        filename = "/" + filename
    
    # find file id
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    
    # get partition name
    if(not partitionExists(str(tableName[0][0]), partition)):
        return "partition does not exist"
    sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(partition)
    cursor.execute(sql)
    db.commit()
    partitionTable = cursor.fetchall()
    cursor.execute("SHOW columns FROM "+ partitionTable[0][0])
    columns = [column[0] for column in cursor.fetchall()]
    
    sql = "SELECT * FROM " + str(partitionTable[0][0])
    cursor.execute(sql)
    result = cursor.fetchall()
    df = pd.DataFrame(result, columns=columns)
    df['json'] = df.apply(lambda x: x.to_json(), axis=1)

    result = []
    for i in range(len(df)):
        result.append(df.loc[i, "json"])

    return jsonify(result)


# @mysql_api.route(f"{MYSQL_API_BASE}/countrydeathcount")
# def search_deathsByCountryAndDataset():
#     country = request.args.get("country")
#     disease = request.args.get("dataset")
#     total = 0
    
#     if(disease == "ebola"):
#         # ebola_2014_2016_clean.csv DEATHS ARE CUMALITIVE?
#         print("\nGetting partition ids for 'ebola_2014_2016_clean.csv'...\n")
#         x = len(_getPartitionLocations('/ebola/ebola_2014_2016_clean.csv'))

#         # find file id
#         filename = '/ebola/ebola_2014_2016_clean.csv'
#         sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
#         cursor.execute(sql)
#         tableName = cursor.fetchall()
#         dfs = []
#         for i in range(x):
#             # get partition name
#             if(not partitionExists(str(tableName[0][0]), i+1)):
#                 return "partition does not exist"
#             sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
#             cursor.execute(sql)
#             db.commit()
#             partitionTable = cursor.fetchall()

#             sql = "SELECT Country, Cumulativenoofconfirmedprobableandsuspecteddeaths FROM " + str(partitionTable[0][0]) + " WHERE Country LIKE '" + country + "' GROUP BY Country"
#             cursor.execute(sql)
#             result = cursor.fetchall()
#             df = pd.DataFrame(result)
#             df.columns = ["country", "deaths"]
#             df['deaths'] = df['deaths'].astype('float')
#             dfs.append(df)
#             db.commit()
#         fdf = pd.concat(dfs)
#         print(fdf, "\n")
#         if(not fdf.empty):
#             r = fdf.groupby(["country"])['deaths'].max().reset_index()
#             print(r)
#             total = total + r['deaths'][0]
#     elif(disease == "sars"):
#         # sars/sars_2003_complete_dataset_clean.csv 
#         print("\nGetting partition ids for 'sars_2003_complete_dataset_clean.csv'...\n")
#         x = len(_getPartitionLocations('/sars/sars_2003_complete_dataset_clean.csv'))

#         # find file id
#         filename = '/sars/sars_2003_complete_dataset_clean.csv'
#         sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
#         cursor.execute(sql)
#         tableName = cursor.fetchall()
#         dfs = []
#         for i in range(x):
#             # get partition name
#             if(not partitionExists(str(tableName[0][0]), i+1)):
#                 return "partition does not exist"
#             sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
#             cursor.execute(sql)
#             db.commit()
#             partitionTable = cursor.fetchall()

#             sql = "SELECT Country, Date, Numberofdeaths FROM " + str(partitionTable[0][0]) + " WHERE Country LIKE '" + country + "'  GROUP BY Country"
#             cursor.execute(sql)
#             result = cursor.fetchall()
#             df = pd.DataFrame(result)
#             if(not df.empty):
#                 df.columns = ["country", "deaths"]
#                 df['deaths'] = df['deaths'].astype('int')
#             dfs.append(df)
#             db.commit()
#         fdf = pd.concat(dfs)
#         print(fdf, "\n")
#         if(not fdf.empty):
#             r = fdf.groupby(["country"])['deaths'].sum().reset_index()
#             print(r)
#             total = total + r['deaths'][0]
#     else:
#          # covid19_clean_complete
#         print("\nGetting partition ids for 'covid19_clean_complete.csv'...\n")
#         x = len(_getPartitionLocations('/covid/covid_19_clean_complete.csv'))

#         # find file id
#         filename = '/covid/covid_19_clean_complete.csv'
#         sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
#         cursor.execute(sql)
#         tableName = cursor.fetchall()
#         dfs = []
#         for i in range(x):
#             # get partition name
#             if(not partitionExists(str(tableName[0][0]), i+1)):
#                 return "partition does not exist"
#             sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
#             cursor.execute(sql)
#             db.commit()
#             partitionTable = cursor.fetchall()

#             sql = "SELECT CountryRegion, Deaths FROM " + str(partitionTable[0][0]) + " WHERE CountryRegion LIKE '" + country + "'  GROUP BY CountryRegion"
#             cursor.execute(sql)
#             result = cursor.fetchall()
#             df = pd.DataFrame(result)
#             if(not df.empty):
#                 df.columns = ["country", "deaths"]
#                 df['deaths'] = df['deaths'].astype('int')
#             dfs.append(df)
#             db.commit()
#         fdf = pd.concat(dfs)
#         print(fdf,"\n")
#         if(not fdf.empty):
#             r = fdf.groupby(["country"])['deaths'].sum().reset_index()
#             print(r)
#             total = total + r['deaths'][0]
        
#     return jsonify(f"Total Deaths in <span class='text-uppercase fw-bold'>{country}</span> for <span class='text-uppercase fw-bold'>{disease}</span>: <span class='text-uppercase fw-bold'>{total}</span>")
    

@mysql_api.route(f"{MYSQL_API_BASE}/countrydeathcount")
def search_deathsByCountryAndDataset():
    country = request.args.get("country")
    disease = request.args.get("dataset")
    total = 0
    
    if(disease == "ebola"):
        # ebola_2014_2016_clean.csv DEATHS ARE CUMALITIVE?
        print("\nGetting partition ids for 'ebola_2014_2016_clean.csv'...\n")
        x = len(_getPartitionLocations('/ebola/ebola_2014_2016_clean.csv'))

        # find file id
        filename = '/ebola/ebola_2014_2016_clean.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []
        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT Country, Cumulativenoofconfirmedprobableandsuspecteddeaths FROM " + str(partitionTable[0][0]) + " WHERE Country LIKE '" + country + "' GROUP BY Country"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "deaths"]
                df['deaths'] = df['deaths'].astype('float')
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        print(fdf, "\n")
        if(not fdf.empty):
            r = fdf.groupby(["country"])['deaths'].max().reset_index()
            print(r)
            total = total + r['deaths'][0]
    elif(disease == "sars"):
        # sars/sars_2003_complete_dataset_clean.csv 
        print("\nGetting partition ids for 'sars_2003_complete_dataset_clean.csv'...\n")
        x = len(_getPartitionLocations('/sars/sars_2003_complete_dataset_clean.csv'))

        # find file id
        filename = '/sars/sars_2003_complete_dataset_clean.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []
        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT Country, Numberofdeaths FROM " + str(partitionTable[0][0]) + " WHERE Country LIKE '" + country + "'  GROUP BY Country"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "deaths"]
                df['deaths'] = df['deaths'].astype('int')
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        print(fdf, "\n")
        if(not fdf.empty):
            r = fdf.groupby(["country"])['deaths'].sum().reset_index()
            print(r)
            total = total + r['deaths'][0]
    else:
         # covid19_clean_complete
        print("\nGetting partition ids for 'covid19_clean_complete.csv'...\n")
        x = len(_getPartitionLocations('/covid/covid_19_clean_complete.csv'))

        # find file id
        filename = '/covid/covid_19_clean_complete.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []
        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT CountryRegion, Deaths FROM " + str(partitionTable[0][0]) + " WHERE CountryRegion LIKE '" + country + "'  GROUP BY CountryRegion"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "deaths"]
                df['deaths'] = df['deaths'].astype('int')
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        print(fdf,"\n")
        if(not fdf.empty):
            r = fdf.groupby(["country"])['deaths'].sum().reset_index()
            print(r)
            total = total + r['deaths'][0]
        
    
    print("\n\nTotal Deaths for " + country + ": " + str(total))
    return jsonify(f"Total Deaths in <span class='text-uppercase fw-bold'>{country}</span> for <span class='text-uppercase fw-bold'>{disease}</span>: <span class='text-uppercase fw-bold'>{total}</span>")
    

@mysql_api.route(f"{MYSQL_API_BASE}/findcountriesbetween")
def countries_casesBetweenXY():
    dataset = request.args.get("dataset")
    limit1 = request.args.get("limit1")
    limit2 = request.args.get("limit2")

    total = []

    if dataset == "ebola":

        # ebola_2014_2016_clean.csv DEATHS ARE CUMALITIVE?
        print("\nGetting partition ids for 'ebola_2014_2016_clean.csv'...\n")
        x = len(_getPartitionLocations('/ebola/ebola_2014_2016_clean.csv'))

        # find file id
        filename = '/ebola/ebola_2014_2016_clean.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []

        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT Country, SUM(Cumulativenoofconfirmedprobableandsuspectedcases) FROM " + str(partitionTable[0][0]) + " GROUP BY Country"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "cases"]
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        if(not fdf.empty):
            r = fdf.groupby(["country"])['cases'].sum().reset_index()
        print(fdf)
        total.append(r)

    elif dataset == "sars":
    
        # sars/sars_2003_complete_dataset_clean.csv
        print("\nGetting partition ids for 'sars/sars_2003_complete_dataset_clean.csv'...\n")
        x = len(_getPartitionLocations('/sars/sars_2003_complete_dataset_clean.csv'))
        
        # find file id
        filename = '/sars/sars_2003_complete_dataset_clean.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []
        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT Country, SUM(Cumulativenumberofcases) FROM " + str(partitionTable[0][0]) + " GROUP BY Country"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "cases"]
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        if(not fdf.empty):
            r = fdf.groupby(["country"])['cases'].sum().reset_index()
        print(fdf)
        total.append(r)

    elif dataset == "covid":
    
    
        # covid/covid_19_clean_complete.csv
        print("\nGetting partition ids for 'covid/covid_19_clean_complete.csv'...\n")
        x = len(_getPartitionLocations('/covid/covid_19_clean_complete.csv'))
        
        # find file id
        filename = '/covid/covid_19_clean_complete.csv'
        sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
        cursor.execute(sql)
        tableName = cursor.fetchall()
        dfs = []
        for i in range(x):
            # get partition name
            if(not partitionExists(str(tableName[0][0]), i+1)):
                return "partition does not exist"
            sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
            cursor.execute(sql)
            db.commit()
            partitionTable = cursor.fetchall()

            sql = "SELECT CountryRegion, SUM(Confirmed) FROM " + str(partitionTable[0][0]) + " GROUP BY CountryRegion"
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result)
            if(not df.empty):
                df.columns = ["country", "cases"]
            dfs.append(df)
            db.commit()
        fdf = pd.concat(dfs)
        if(not fdf.empty):
            r = fdf.groupby(["country"])['cases'].sum().reset_index()
        print(fdf)
        total.append(r)
    
    print(f"\n\n Countries with cases between {limit1} and {limit2}")
    final = pd.concat(total)
    final.columns = ["country", "cases"]
    filtering = final.groupby(["country"])['cases'].sum().reset_index()

    result = filtering.query(f'cases > {limit1} & cases < {limit2}')
    result['json'] = result.apply(lambda x: x.to_json(), axis=1)

    output = []
    for _, row in result.iterrows():
        output.append(row["json"])

    return jsonify(output)


@mysql_api.route(f"{MYSQL_API_BASE}/analysisdeathpercountry")
def totalNumberofDeathsPerCountry():
    # ebola_2014_2016_clean.csv DEATHS ARE CUMALITIVE?
    print("\nGetting partition ids for 'ebola_2014_2016_clean.csv'...\n")
    x = len(_getPartitionLocations('/ebola/ebola_2014_2016_clean.csv'))
    total = []
    # find file id
    filename = '/ebola/ebola_2014_2016_clean.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()

        sql = "SELECT Country, SUM(Cumulativenoofconfirmedprobableandsuspecteddeaths) FROM " + str(partitionTable[0][0]) + " GROUP BY Country"
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["country", "deaths"]
        dfs.append(df)
        db.commit()
    fdf = pd.concat(dfs)
    if(not fdf.empty):
        r = fdf.groupby(["country"])['deaths'].sum().reset_index()
        print(r)
    total.append(r)
    
    # sars/sars_2003_complete_dataset_clean.csv
    print("\nGetting partition ids for 'sars/sars_2003_complete_dataset_clean.csv'...\n")
    x = len(_getPartitionLocations('/sars/sars_2003_complete_dataset_clean.csv'))
    
    # find file id
    filename = '/sars/sars_2003_complete_dataset_clean.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()

        sql = "SELECT Country, SUM(Numberofdeaths) FROM " + str(partitionTable[0][0]) + " GROUP BY Country"
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["country", "deaths"]
        dfs.append(df)
        db.commit()
    fdf = pd.concat(dfs)
    if(not fdf.empty):
        r = fdf.groupby(["country"])['deaths'].sum().reset_index()
        print(r)
    total.append(r)
    
    # covid/covid_19_clean_complete.csv
    print("\nGetting partition ids for 'covid/covid_19_clean_complete.csv'...\n")
    x = len(_getPartitionLocations('/covid/covid_19_clean_complete.csv'))
    
    # find file id
    filename = '/covid/covid_19_clean_complete.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()

        sql = "SELECT CountryRegion, SUM(Deaths) FROM " + str(partitionTable[0][0]) + " GROUP BY CountryRegion"
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["country", "deaths"]
        dfs.append(df)
        db.commit()
    fdf = pd.concat(dfs)
    if(not fdf.empty):
        r = fdf.groupby(["country"])['deaths'].sum().reset_index()
    print(fdf)
    total.append(r)
    
    final = pd.concat(total)
    final.columns = ["country", "deaths"]
    filtering = final.groupby(["country"])['deaths'].sum().reset_index()
    print("\n\nTotal number of deaths per country...")
    
    result = filtering
    result['json'] = result.apply(lambda x: x.to_json(), axis=1)

    output = []
    for _, row in result.iterrows():
        output.append(row["json"])

    return jsonify(output)


@mysql_api.route(f"{MYSQL_API_BASE}/analysisrecovery")
def averageNumberofRecoveredPerOutbreak():
    
    x = len(_getPartitionLocations('/ebola/ebola_2014_2016_clean.csv'))
    # find file id
    filename = '/ebola/ebola_2014_2016_clean.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    parts = []
    ebola_final = [0,0]
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()
        cursor.execute("ALTER TABLE "+ str(partitionTable[0][0]) + " MODIFY Cumulativenoofconfirmedprobableandsuspectedcases INTEGER")
        sql = "SELECT Country, MAX(Cumulativenoofconfirmedprobableandsuspectedcases), Cumulativenoofconfirmedprobableandsuspectedcases - Cumulativenoofconfirmedprobableandsuspecteddeaths as recovered FROM " + str(partitionTable[0][0]) + " GROUP BY Country"
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["country", "cases", "recovered"]
            part = [int(df['recovered'].mean()), int(df['cases'].mean())]
            ebola_final[0] = ebola_final[0] + df['recovered'].mean()
            ebola_final[1] = ebola_final[1] + df['cases'].mean()
            parts.append(part)
        dfs.append(df)
        db.commit()
    ebola_parts = parts
    ebola_final[0] = int(ebola_final[0]/x)
    ebola_final[1] = int(ebola_final[1]/x)

    # sars/sars_2003_complete_dataset_clean.csv
    x = len(_getPartitionLocations('/sars/sars_2003_complete_dataset_clean.csv'))
    parts = []
    sars_final = [0,0]
    # find file id
    filename = '/sars/sars_2003_complete_dataset_clean.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()

        sql = "SELECT AVG(Cumulativenumberofcases), AVG(Numberrecovered) FROM " + str(partitionTable[0][0]) 
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["cases", "recovered"]
            part = [int(df['recovered'].mean()), int(df['cases'].mean())]
            sars_final[0] = sars_final[0] + df['recovered'].mean()
            sars_final[1] = sars_final[1] + df['cases'].mean()
            parts.append(part)
        dfs.append(df)
        db.commit()
    sars_parts = parts
    sars_final[0] = int(sars_final[0]/x)
    sars_final[1] = int(sars_final[1]/x)
    
    # covid/covid_19_clean_complete.csv
    x = len(_getPartitionLocations('/covid/covid_19_clean_complete.csv'))
    parts = []
    covid_final = [0,0]
    # find file id
    filename = '/covid/covid_19_clean_complete.csv'
    sql = "SELECT file FROM dir WHERE content LIKE '" + filename + "'"
    cursor.execute(sql)
    tableName = cursor.fetchall()
    dfs = []
    for i in range(x):
        # get partition name
        if(not partitionExists(str(tableName[0][0]), i+1)):
            return "partition does not exist"
        sql = "SELECT partition_name FROM partitions WHERE tableName LIKE '" + str(tableName[0][0]) +"' AND part = " + str(i+1)
        cursor.execute(sql)
        db.commit()
        partitionTable = cursor.fetchall()

        sql = "SELECT AVG(Confirmed), AVG(Recovered) FROM " + str(partitionTable[0][0])
        cursor.execute(sql)
        result = cursor.fetchall()
        df = pd.DataFrame(result)
        if(not df.empty):
            df.columns = ["cases", "recovered"]
            part = [int(df['recovered'].mean()), int(df['cases'].mean())]
            covid_final[0] = covid_final[0] + df['recovered'].mean()
            covid_final[1] = covid_final[1] + df['cases'].mean()
            parts.append(part)
        dfs.append(df)
        db.commit()
    covid_parts = parts
    covid_final[0] = int(covid_final[0]/x)
    covid_final[1] = int(covid_final[1]/x)
    
    final = {"mapper": {"sars": sars_parts, "ebola": ebola_parts, "covid": covid_parts},"reducer":{"sars": sars_final, "ebola": ebola_final, "covid": covid_final}}
    print(final)
    return jsonify(final)
